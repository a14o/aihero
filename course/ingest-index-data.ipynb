{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "448ecd0c-a588-4d12-bee7-d9a6e7dee668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "import frontmatter\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62535ae0-f4ce-4a2a-bb38-85bf58c657f0",
   "metadata": {},
   "source": [
    "# Ingest and Index Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e146cc18-075c-4459-af9a-09c65799f3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_repo_data(repo_owner, repo_name):\n",
    "    \"\"\"\n",
    "    Download and parse all markdown files from a GitHub repository.\n",
    "    \n",
    "    Args:\n",
    "        repo_owner: GitHub username or organization\n",
    "        repo_name: Repository name\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries containing file content and metadata\n",
    "    \"\"\"\n",
    "    prefix = 'https://codeload.github.com' \n",
    "    url = f'{prefix}/{repo_owner}/{repo_name}/zip/refs/heads/main'\n",
    "    resp = requests.get(url)\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(f\"Failed to download repository: {resp.status_code}\")\n",
    "\n",
    "    repository_data = []\n",
    "    zf = zipfile.ZipFile(io.BytesIO(resp.content))\n",
    "    \n",
    "    for file_info in zf.infolist():\n",
    "        filename = file_info.filename\n",
    "        filename_lower = filename.lower()\n",
    "\n",
    "        if not (filename_lower.endswith('.md') \n",
    "            or filename_lower.endswith('.mdx')):\n",
    "            continue\n",
    "    \n",
    "        try:\n",
    "            with zf.open(file_info) as f_in:\n",
    "                content = f_in.read().decode('utf-8', errors='ignore')\n",
    "                post = frontmatter.loads(content)\n",
    "                data = post.to_dict()\n",
    "                data['filename'] = filename\n",
    "                repository_data.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    zf.close()\n",
    "    return repository_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "764ba806-8d30-45b2-aca4-fa1d44f1fde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAQ documents: 1219\n",
      "Evidently documents: 95\n"
     ]
    }
   ],
   "source": [
    "dtc_faq = read_repo_data('DataTalksClub', 'faq')\n",
    "evidently_docs = read_repo_data('evidentlyai', 'docs')\n",
    "\n",
    "print(f\"FAQ documents: {len(dtc_faq)}\")\n",
    "print(f\"Evidently documents: {len(evidently_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f583a096-1160-4db2-838a-a539eb05d6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: docs-main/examples/LLM_regression_testing.mdx\n",
      "Metadata: {}\n",
      "Content preview:\n",
      "In this tutorial, you will learn how to perform regression testing for LLM outputs.\n",
      "\n",
      "You can compare new and old responses after changing a prompt, model, or anything else in your system. By re-running the same inputs with new parameters, you can spot any significant changes. This helps you push updates with confidence or identify issues to fix.\n",
      "\n",
      "<Info>\n",
      "  **This example uses Evidently Cloud.** You'll run evals in Python and upload them. You can also skip the upload and view Reports locally. For self-hosted, replace `CloudWorkspace` with `Workspace`.\n",
      "</Info>\n",
      "\n",
      "# Tutorial scope\n",
      "\n",
      "Here's what we'll do:\n",
      "\n",
      "* **Create a toy dataset**. Build a small Q&A dataset with answers and reference responses.\n",
      "\n",
      "* **Get new answers**. Imitate generating new answers to the same question.\n",
      "\n",
      "* **Create and run a Report with Tests**. Compare the answers using LLM-as-a-judge to evaluate length, correctness and style consistency.\n",
      "\n",
      "* **Build a monitoring Dashboard**. Get plots to track the results of Tests over time...\n"
     ]
    }
   ],
   "source": [
    "# Previews Evidently document at index 45\n",
    "evidently_doc = evidently_docs[45]\n",
    "print(f\"Filename: {evidently_doc['filename']}\")\n",
    "print(f\"Metadata: {evidently_doc.get('attributes', {})}\")\n",
    "print(f\"Content preview:\\n{evidently_doc['content'][:1000]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aa66dd-d551-4af6-8f1c-7e9fed02fac2",
   "metadata": {},
   "source": [
    "# Simple Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a60d30ba-a9c7-40dc-ad9a-9f4080225818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(seq, size, step):\n",
    "    if size <= 0 or step <= 0:\n",
    "        raise ValueError(\"size and step must be positive\")\n",
    "\n",
    "    n = len(seq)\n",
    "    result = []\n",
    "    for i in range(0, n, step):\n",
    "        chunk = seq[i:i+size]\n",
    "        result.append({'start': i, 'chunk': chunk})\n",
    "        if i + size >= n:\n",
    "            break\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "589ab8a5-e8b2-4c2f-85ff-519b4140ebfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidently_chunks = []\n",
    "\n",
    "for doc in evidently_docs:\n",
    "    doc_copy = doc.copy()\n",
    "    doc_content = doc_copy.pop('content')\n",
    "    chunks = sliding_window(doc_content, 2000, 1000)\n",
    "    for chunk in chunks:\n",
    "        chunk.update(doc_copy)\n",
    "    evidently_chunks.extend(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c0510a9-3305-4932-841c-bf67880f85f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Chunk 0 ---\n",
      "Filename: docs-main/api-reference/introduction.mdx\n",
      "Start Index: 0\n",
      "Content Preview:\n",
      "<Note>\n",
      "  If you're not looking to build API reference documentation, you can delete\n",
      "  this section by removing the api-reference folder.\n",
      "</Note>\n",
      "\n",
      "## Welcome\n",
      "\n",
      "There are two ways to build API documentation: [OpenAPI](https://mintlify.com/docs/api-playground/openapi/setup) and [MDX components](https://mintlify.com/docs/api-playground/mdx/configuration). For the starter kit, we are using the following OpenAPI specification.\n",
      "\n",
      "<Card\n",
      "  title=\"Plant Store Endpoints\"\n",
      "  icon=\"leaf\"\n",
      "  href=\"https://github.com/mintlify/starter/blob/main/api-reference/openapi.json\"\n",
      ">\n",
      "  View the OpenAPI specification file\n",
      "</Card>\n",
      "\n",
      "## Authentication\n",
      "\n",
      "All API endpoints are authenticated using Bearer tokens and picked up from the specification file.\n",
      "\n",
      "```json\n",
      "\"security\": [\n",
      "  {\n",
      "    \"bearerAuth\": []\n",
      "  }\n",
      "]\n",
      "```...\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Filename: docs-main/changelog/changelog.mdx\n",
      "Start Index: 0\n",
      "Content Preview:\n",
      "<Update label=\"2025-07-18\" description=\"Evidently v0.7.11\">\n",
      "  ## **Evidently 0.7.11**\n",
      "\n",
      "  Full release notes on [Github](https://github.com/evidentlyai/evidently/releases/tag/v0.7.11).\n",
      "\n",
      "Example notebooks:\n",
      "- Synthetic data generation: [code example](https://github.com/evidentlyai/evidently/blob/main/examples/cookbook/datagen.ipynb)\n",
      "\n",
      "</Update>\n",
      "\n",
      "<Update label=\"2025-07-09\" description=\"Evidently v0.7.10\">\n",
      "  ## **Evidently 0.7.10**\n",
      "    Full release notes on [Github](https://github.com/evidentlyai/evidently/releases/tag/v0.7.10).\n",
      "  \n",
      "NEW: automated prompt optimization. Read the release blog on [prompt optimization for LLM judges](https://www.evidentlyai.com/blog/llm-judge-prompt-optimization).\n",
      "\n",
      "Example notebooks:\n",
      "- Code review binary LLM judge prompt optimization: [code example](https://github.com/evidentlyai/evidently/blob/main/examples/cookbook/prompt_optimization_code_review_example.ipynb)\n",
      "- Topic multi-class LLM judge prompt optimization: [code example](https://github.com/evidentlyai/evide...\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Filename: docs-main/changelog/changelog.mdx\n",
      "Start Index: 1000\n",
      "Content Preview:\n",
      "ntly/blob/main/examples/cookbook/prompt_optimization_bookings_example.ipynb)\n",
      "- Tweet generation prompt optimization: [code example](https://github.com/evidentlyai/evidently/blob/main/examples/cookbook/prompt_optimization_tweet_generation_example.ipynb)\n",
      "</Update>\n",
      "\n",
      "<Update label=\"2025-06-27\" description=\"Evidently v0.7.9\">\n",
      "  ## **Evidently 0.7.9**\n",
      "\n",
      "  Full release notes on [Github](https://github.com/evidentlyai/evidently/releases/tag/v0.7.9).\n",
      "</Update>\n",
      "\n",
      "<Update label=\"2025-06-19\" description=\"Evidently v0.7.8\">\n",
      "  ## **Evidently 0.7.8**\n",
      "\n",
      "  Full release notes on [Github](https://github.com/evidentlyai/evidently/releases/tag/v0.7.8).\n",
      "</Update>\n",
      "\n",
      "<Update label=\"2025-06-04\" description=\"Evidently v0.7.7\">\n",
      "  ## **Evidently 0.7.7**\n",
      "\n",
      "  Full release notes on [Github](https://github.com/evidentlyai/evidently/releases/tag/v0.7.7).\n",
      "</Update>\n",
      "\n",
      "<Update label=\"2025-05-25\" description=\"Evidently v0.7.6\">\n",
      "  ## **Evidently 0.7.6**\n",
      "\n",
      "  Full release notes on [Github](https://github.com/evidentlyai/evidently/r...\n"
     ]
    }
   ],
   "source": [
    "# Preview first 3 chunks\n",
    "for i, chunk in enumerate(evidently_chunks[:3]):\n",
    "    print(f\"\\n--- Chunk {i} ---\")\n",
    "    print(f\"Filename: {chunk.get('filename')}\")\n",
    "    print(f\"Start Index: {chunk['start']}\")\n",
    "    print(f\"Content Preview:\\n{chunk['chunk'][:1000]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0155ce-95ff-431f-9e33-667068177635",
   "metadata": {},
   "source": [
    "# Split by Paragraphs and Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e14e0f1-8ef8-4daa-8500-f83b9ddc616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simple document files\n",
    "text = evidently_docs[45]['content']\n",
    "paragraphs = re.split(r\"\\n\\s*\\n\", text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46542a13-07e1-412a-a8cf-ac98f5d2bcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_markdown_by_level(text, level=2):\n",
    "    \"\"\"\n",
    "    Split markdown text by a specific header level.\n",
    "    \n",
    "    :param text: Markdown text as a string\n",
    "    :param level: Header level to split on\n",
    "    :return: List of sections as strings\n",
    "    \"\"\"\n",
    "    # This regex matches markdown headers\n",
    "    # For level 2, it matches lines starting with \"## \"\n",
    "    header_pattern = r'^(#{' + str(level) + r'} )(.+)$'\n",
    "    pattern = re.compile(header_pattern, re.MULTILINE)\n",
    "\n",
    "    # Split and keep the headers\n",
    "    parts = pattern.split(text)\n",
    "    \n",
    "    sections = []\n",
    "    for i in range(1, len(parts), 3):\n",
    "        # We step by 3 because regex.split() with\n",
    "        # capturing groups returns:\n",
    "        # [before_match, group1, group2, after_match, ...]\n",
    "        # here group1 is \"## \", group2 is the header text\n",
    "        header = parts[i] + parts[i+1]  # \"## \" + \"Title\"\n",
    "        header = header.strip()\n",
    "\n",
    "        # Get the content after this header\n",
    "        content = \"\"\n",
    "        if i+2 < len(parts):\n",
    "            content = parts[i+2].strip()\n",
    "\n",
    "        if content:\n",
    "            section = f'{header}\\n\\n{content}'\n",
    "        else:\n",
    "            section = header\n",
    "        sections.append(section)\n",
    "    \n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8e2039f-1646-42b6-81dc-8d7270dab17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = split_markdown_by_level(text, level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60e89565-8e26-4784-988a-e4e826d23ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidently_chunks = []\n",
    "\n",
    "for doc in evidently_docs:\n",
    "    doc_copy = doc.copy()\n",
    "    doc_content = doc_copy.pop('content')\n",
    "    sections = split_markdown_by_level(doc_content, level=2)\n",
    "    for section in sections:\n",
    "        section_doc = doc_copy.copy()\n",
    "        section_doc['section'] = section\n",
    "        evidently_chunks.append(section_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c37295c-6068-4712-a174-4f4fb301aaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sections (chunks) extracted: 262\n",
      "\n",
      "--- Chunk 0 ---\n",
      "Filename: docs-main/api-reference/introduction.mdx\n",
      "Metadata: {}\n",
      "Section Preview:\n",
      "## Welcome\n",
      "\n",
      "There are two ways to build API documentation: [OpenAPI](https://mintlify.com/docs/api-playground/openapi/setup) and [MDX components](https://mintlify.com/docs/api-playground/mdx/configuration). For the starter kit, we are using the following OpenAPI specification.\n",
      "\n",
      "<Card\n",
      "  title=\"Plant Store Endpoints\"\n",
      "  icon=\"leaf\"\n",
      "  href=\"https://github.com/mintlify/starter/blob/main/api-reference/openapi.json\"\n",
      ">\n",
      "  View the OpenAPI specification file\n",
      "</Card>...\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Filename: docs-main/api-reference/introduction.mdx\n",
      "Metadata: {}\n",
      "Section Preview:\n",
      "## Authentication\n",
      "\n",
      "All API endpoints are authenticated using Bearer tokens and picked up from the specification file.\n",
      "\n",
      "```json\n",
      "\"security\": [\n",
      "  {\n",
      "    \"bearerAuth\": []\n",
      "  }\n",
      "]\n",
      "```...\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Filename: docs-main/docs/library/data_definition.mdx\n",
      "Metadata: {}\n",
      "Section Preview:\n",
      "## Basic flow\n",
      "\n",
      "**Step 1. Imports.** Import the following modules:\n",
      "\n",
      "```python\n",
      "from evidently import Dataset\n",
      "from evidently import DataDefinition\n",
      "```\n",
      "\n",
      "**Step 2. Prepare your data.** Use a pandas.DataFrame.\n",
      "\n",
      "<Info>\n",
      "  Your data can have [flexible structure](/docs/library/overview#dataset) with any mix of categorical, numerical or text columns. Check the [Reference table](/metrics/all_metrics) for data requirements in specific evaluations.\n",
      "</Info>\n",
      "\n",
      "**Step 3. Create a Dataset object**. Use `Dataset.from_pandas` with `data_definition`:\n",
      "\n",
      "```python\n",
      "eval_data = Dataset.from_pandas(\n",
      "    source_df,\n",
      "    data_definition=DataDefinition()\n",
      ")\n",
      "```\n",
      "\n",
      "To map columns automatically, pass an empty `DataDefinition()` . Evidently will map columns:\n",
      "\n",
      "- By type (numerical, categorical).\n",
      "- By matching column names to roles (e.g., a column \"target\" treated as target).\n",
      "\n",
      "Automation works in many cases, but manual mapping is more accurate. It is also necessary for evaluating prediction quality or handling text columns.\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Preview first 3 chunks\n",
    "print(f\"Total sections (chunks) extracted: {len(evidently_chunks)}\")\n",
    "for i, chunk in enumerate(evidently_chunks[:3]):\n",
    "    print(f\"\\n--- Chunk {i} ---\")\n",
    "    print(f\"Filename: {chunk.get('filename')}\")\n",
    "    print(f\"Metadata: {chunk.get('attributes', {})}\")\n",
    "    print(f\"Section Preview:\\n{chunk['section'][:1000]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f1db34-1a3c-4363-a70a-f37492023a47",
   "metadata": {},
   "source": [
    "# Intelligent Chunking with LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31180f96-501c-4fd4-ae2b-823f0a7eee82",
   "metadata": {},
   "source": [
    "Models used:\n",
    "- x-ai/grok-4-fast:free\n",
    "- deepseek/deepseek-chat-v3.1:free\n",
    "- google/gemma-3n-e2b-it:free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fb8aab7-fbcb-4777-b5f4-fd4359d69e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'gen-1759143822-AZrnbVBjPgy4BcSn7IJb', 'provider': 'Google AI Studio', 'model': 'google/gemma-3n-e2b-it:free', 'object': 'chat.completion', 'created': 1759143823, 'choices': [{'logprobs': None, 'finish_reason': 'stop', 'native_finish_reason': 'STOP', 'index': 0, 'message': {'role': 'assistant', 'content': 'Ah, the age-old question! The meaning of life is one of the most pondered and debated topics in human history, and there\\'s no single, universally accepted answer. It\\'s a deeply personal and philosophical exploration. Here\\'s a breakdown of different perspectives, ranging from philosophical to religious to scientific, and a few thoughts on how you might find *your* meaning:\\n\\n**1. Philosophical Perspectives:**\\n\\n*   **Nihilism:** This view argues that life is inherently without objective meaning, purpose, or intrinsic value. There\\'s no cosmic plan or destiny.  While seemingly bleak, some find freedom in this by accepting the lack of inherent meaning and creating their own.\\n*   **Existentialism:**  Central to existentialism is the idea that existence precedes essence.  We are born into the world without a predetermined purpose, and it\\'s up to us to create our own meaning through our choices and actions.  Key figures include Jean-Paul Sartre and Albert Camus.  Focus is on individual responsibility and authenticity. \"Existence precedes essence.\" \\n*   **Absurdism:**  Related to existentialism, absurdism acknowledges the fundamental conflict between humanity\\'s desire for meaning and the universe\\'s apparent meaninglessness. Instead of seeking a solution, absurdists embrace the absurdity and find joy in rebellion and living fully in the face of it. (Camus)\\n*   **Hedonism:**  Focuses on maximizing pleasure and minimizing pain as the ultimate goal and source of meaning.  This can range from simple sensory pleasures to more refined intellectual and emotional gratifications.  (Aristotle had a version of this, but it wasn\\'t purely about pleasure). \\n*   **Stoicism:**  Emphasizes virtue, reason, and living in accordance with nature. Finding meaning comes from accepting what you cannot control, focusing on your own character, and fulfilling your duties to others.  (Epictetus, Marcus Aurelius)\\n*  **Humanism:** Emphasizes human agency and reason.  Meaning is found in human relationships, contribution to society, pursuit of knowledge, and ethical behavior.\\n\\n**2. Religious Perspectives:**\\n\\n*   **Many Religions:**  Most religions offer a meaning of life centered around a divine being or higher power. Common themes include:\\n    *   **Serving God/a Higher Power:**  Fulfilling a divine purpose, obeying religious laws, and striving for spiritual growth.\\n    *   **Achieving Enlightenment:**  Reaching a state of understanding and oneness with the universe.\\n    *   **Karma and Reincarnation:**  Living a life that leads to a better future or a cycle of rebirth, focused on ethical conduct.\\n    *   **Salvation/Redemption:**  Being rescued from suffering and achieving eternal life.\\n    *   Specific religions have varying beliefs about the nature of life, death, and the afterlife. (Christianity, Islam, Hinduism, Buddhism, Judaism, etc.)\\n\\n**3. Scientific Perspectives:**\\n\\n*   **Evolutionary Biology:**  From a purely scientific standpoint, the \"meaning\" of life could be seen as survival and reproduction – passing on genes to the next generation. But biologists generally don\\'t consider this to be *meaningful* in a human sense.\\n*   **Neuroscience:** Neuroscience explores the biological basis of consciousness, emotions, and behavior. It doesn\\'t offer a grand meaning of life but helps us understand *why* we experience the world the way we do.  The purpose of life, according to neuroscience, is likely related to maximizing well-being and minimizing suffering, driven by evolutionary pressures.\\n*   **Cosmology:** The universe is vast and ancient, and our place in it is often perceived as small.  Cosmological perspectives don\\'t inherently offer meaning; however, they can inspire awe and a sense of wonder, prompting individuals to seek meaning within that context.\\n\\n\\n**4.  Personal Perspectives – How to Find *Your* Meaning:**\\n\\nThis is where things get really interesting and personal!  Here are some ideas:\\n\\n*   **Relationships:** Connecting with others – family, friends, romantic partners – and building meaningful relationships.\\n*   **Contribution:** Making a positive impact on the world, however small. This could involve volunteering, activism, creative endeavors, or simply acts of kindness.\\n*   **Growth:**  Continuously learning, developing your skills, and striving to become the best version of yourself.\\n*   **Experiences:**  Seeking out new adventures, exploring the world, and immersing yourself in different cultures.\\n*   **Creativity:** Expressing yourself through art, music, writing, or any other form of creative expression.\\n*   **Values:**  Identifying what\\'s truly important to you – honesty, integrity, justice, compassion – and living in accordance with those values.\\n*   **Finding Joy:**  Simply appreciating the beauty and wonder of life, and finding moments of joy in everyday experiences.\\n*  **Purposeful Work:**  Finding work that feels meaningful and aligned with your values.\\n\\n**Important Considerations:**\\n\\n*   **It\\'s a journey, not a destination.** The meaning of life isn\\'t something you *find* once and for all. It\\'s something you *create* and evolve throughout your life.\\n*   **Meaning can change over time.** What feels meaningful to you at one stage of your life may not feel the same at another.\\n*   **There\\'s no right or wrong answer.** What matters is what resonates with *you*.\\n\\n\\n\\n**In conclusion:** The meaning of life isn\\'t a pre-packaged answer. It\\'s a question you must answer for yourself. Explore different perspectives, reflect on your values and experiences, and create a meaning that feels authentic and fulfilling.\\n\\n\\n\\nTo help me tailor my answer further, is there anything specific you\\'re curious about?  For example:\\n\\n* Are you interested in a particular philosophical school of thought?\\n* Are you struggling with a feeling of meaninglessness?\\n* Do you have a particular area of life you\\'re focusing on (relationships, career, etc.)?\\n\\n\\n\\n', 'refusal': None, 'reasoning': None}}], 'usage': {'prompt_tokens': 8, 'completion_tokens': 1302, 'total_tokens': 1310, 'prompt_tokens_details': {'cached_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'image_tokens': 0}}}\n"
     ]
    }
   ],
   "source": [
    "# Go up to root directory\n",
    "env_path = Path(os.getcwd()).parents[0] / '.env'\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Get the API key from environment variable\n",
    "api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "# Check if API key was loaded\n",
    "if not api_key:\n",
    "    raise Exception(\"OPENROUTER_API_KEY not found in .env file\")\n",
    "\n",
    "# Send the request\n",
    "response = requests.post(\n",
    "    url=\"https://openrouter.ai/api/v1/chat/completions\",\n",
    "    headers={\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    },\n",
    "    data=json.dumps({\n",
    "        \"model\": \"google/gemma-3n-e2b-it:free\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the meaning of life?\"\n",
    "            }\n",
    "        ]\n",
    "    })\n",
    ")\n",
    "\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3520a0f4-ff96-48f9-948b-ed53f560704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM call via OpenRouter\n",
    "def llm(prompt, model='google/gemma-3n-e2b-it:free'):\n",
    "    url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"ERROR:\", response.status_code, response.text)\n",
    "        return \"\"\n",
    "\n",
    "    response_json = response.json()\n",
    "    return response_json['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a99759d8-45a6-47ca-9ee1-0d1dbc945c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt template for chunking\n",
    "prompt_template = \"\"\"\n",
    "Split the provided document into logical sections\n",
    "that make sense for a Q&A system.\n",
    "\n",
    "Each section should be self-contained and cover\n",
    "a specific topic or concept.\n",
    "\n",
    "<DOCUMENT>\n",
    "{document}\n",
    "</DOCUMENT>\n",
    "\n",
    "Use this format:\n",
    "\n",
    "## Section Name\n",
    "\n",
    "Section content with all relevant details\n",
    "\n",
    "---\n",
    "\n",
    "## Another Section Name\n",
    "\n",
    "Another section content\n",
    "\n",
    "---\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be3349b0-0ef8-4067-9f1b-3b86b44e43a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunking logic\n",
    "def intelligent_chunking(text):\n",
    "    prompt = prompt_template.format(document=text)\n",
    "    response = llm(prompt)\n",
    "    sections = response.split('---')\n",
    "    sections = [s.strip() for s in sections if s.strip()]\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13793776-68e4-44ea-9418-41ee7435359b",
   "metadata": {},
   "outputs": [],
   "source": [
    "evidently_chunks = []\n",
    "\n",
    "for doc in tqdm(evidently_docs):\n",
    "    doc_copy = doc.copy()\n",
    "    doc_content = doc_copy.pop('content')\n",
    "\n",
    "    sections = intelligent_chunking(doc_content)\n",
    "    for section in sections:\n",
    "        section_doc = doc_copy.copy()\n",
    "        section_doc['section'] = section\n",
    "        evidently_chunks.append(section_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbb552c-2808-4d1b-bb81-c117848153fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the chunks for inspection\n",
    "for chunk in evidently_chunks[:5]:\n",
    "    print(\"Section from:\", chunk['title'])\n",
    "    print(chunk['section'])\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f89ef88-ddfa-4cb7-bfe4-319e6ead9f00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
